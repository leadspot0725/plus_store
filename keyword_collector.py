import os
import time
import logging
import urllib.parse
import sys
import random
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime

import gspread
import requests
from bs4 import BeautifulSoup
from google.oauth2.service_account import Credentials
from selenium import webdriver
from selenium.webdriver.chrome.options import Options

# CSS ì„ íƒì ì„¤ì • (ìœ ì§€ë³´ìˆ˜ë¥¼ ìœ„í•´ í•œ ê³³ì— ëª¨ìŒ)
SELECTORS = {
    "related_keywords": "span.keywordItem_text__72V9o",  # í˜„ì¬ ì„ íƒì
    "related_keywords_alt": ".relatedTags_relation_tag__M4DGR span",  # ëŒ€ì²´ ì„ íƒì
    "related_keywords_alt2": "div.relatedTags_relation_srh__MMCvd a",  # ì¶”ê°€ ëŒ€ì²´ ì„ íƒì
}

# ë¡œê¹… ì„¤ì •
def setup_logging():
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler("keyword_collector.log"),
            logging.StreamHandler(sys.stdout)
        ]
    )
    return logging.getLogger()

# Google Sheets ì—°ë™ í•¨ìˆ˜
def connect_google_sheet(sheet_id, worksheet_name):
    logger = logging.getLogger()
    service_account_file = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")

    if not service_account_file:
        logger.error("âŒ GOOGLE_APPLICATION_CREDENTIALS í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        raise ValueError("âŒ GOOGLE_APPLICATION_CREDENTIALS í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    try:
        creds = Credentials.from_service_account_file(service_account_file, scopes=[
            "https://spreadsheets.google.com/feeds",
            "https://www.googleapis.com/auth/drive"
        ])
        client = gspread.authorize(creds)
        sheet = client.open_by_key(sheet_id).worksheet(worksheet_name)
        logger.info(f"âœ… Google Sheet '{worksheet_name}' ì—°ê²° ì„±ê³µ")
        return sheet
    except Exception as e:
        logger.error(f"âŒ Google Sheet ì—°ê²° ì‹¤íŒ¨: {e}")
        raise

# ì¼ë°˜ ìš”ì²­ì„ ì‚¬ìš©í•œ í¬ë¡¤ë§ í•¨ìˆ˜
def get_related_keywords(keyword):
    logger = logging.getLogger()
    # URL ì¸ì½”ë”© ì¶”ê°€
    encoded_keyword = urllib.parse.quote(keyword)
    url = f"https://search.shopping.naver.com/search/all?query={encoded_keyword}"
    
    # ë” í˜„ì‹¤ì ì¸ í—¤ë” ì‚¬ìš©
    headers = {
        "User-Agent": f"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/{random.randint(90, 110)}.0.{random.randint(4000, 5000)}.{random.randint(100, 200)} Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
        "Accept-Language": "ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3",
        "Referer": "https://www.naver.com/",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
        "Cache-Control": "max-age=0",
        "sec-ch-ua": "\" Not A;Brand\";v=\"99\", \"Chromium\";v=\"101\", \"Google Chrome\";v=\"101\"",
        "sec-ch-ua-mobile": "?0",
        "sec-ch-ua-platform": "\"Windows\"",
    }
    
    # ìš”ì²­ ì „ì†¡ ë° ì˜ˆì™¸ ì²˜ë¦¬
    try:
        # ìš”ì²­ ê°„ ëœë¤ ì§€ì—° ì¶”ê°€
        time.sleep(random.uniform(1, 3))
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()  # HTTP ì˜¤ë¥˜ ê²€ì‚¬
    except requests.exceptions.RequestException as e:
        logger.warning(f"ìš”ì²­ ì‹¤íŒ¨: {e}")
        return []
    
    soup = BeautifulSoup(response.text, "html.parser")
    
    # ì—¬ëŸ¬ ì„ íƒì ì‹œë„
    related = []
    for selector in [SELECTORS["related_keywords"], SELECTORS["related_keywords_alt"], SELECTORS["related_keywords_alt2"]]:
        related = soup.select(selector)
        if related:
            logger.info(f"âœ… ì„ íƒì '{selector}'ë¡œ {len(related)}ê°œ í‚¤ì›Œë“œ ì°¾ìŒ")
            break
    
    result = [tag.get_text().strip() for tag in related] if related else []
    if not result:
        logger.warning(f"âš ï¸ {keyword}: ì¼ë°˜ ìš”ì²­ìœ¼ë¡œ ì—°ê´€ í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
    return result

# Seleniumì„ í™œìš©í•œ í¬ë¡¤ë§ (ì˜ˆë¹„ìš©)
def get_related_keywords_selenium(keyword):
    logger = logging.getLogger()
    logger.info(f"ğŸ”„ {keyword}: Selenium í¬ë¡¤ë§ ì‹œì‘")
    
    # URL ì¸ì½”ë”©
    encoded_keyword = urllib.parse.quote(keyword)
    url = f"https://search.shopping.naver.com/search/all?query={encoded_keyword}"
    
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    # ëœë¤ ìœ ì € ì—ì´ì „íŠ¸
    user_agent = f"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/{random.randint(90, 110)}.0.{random.randint(4000, 5000)}.{random.randint(100, 200)} Safari/537.36"
    options.add_argument(f"user-agent={user_agent}")
    
    try:
        # ì‹œìŠ¤í…œì— ì„¤ì¹˜ëœ ChromeDriver ì‚¬ìš©
        driver = webdriver.Chrome(options=options)
        driver.set_page_load_timeout(20)
        
        # ë„¤ì´ë²„ ë©”ì¸ í˜ì´ì§€ ë°©ë¬¸ í›„ ê²€ìƒ‰ í˜ì´ì§€ë¡œ ì´ë™ (ë” ìì—°ìŠ¤ëŸ¬ìš´ ì ‘ê·¼)
        driver.get("https://www.naver.com")
        time.sleep(random.uniform(1, 2))
        driver.get(url)
        
        # ëœë¤ ì§€ì—° ì¶”ê°€ (ë´‡ íƒì§€ ìš°íšŒ)
        time.sleep(random.uniform(3, 6))
        
        # ì•½ê°„ì˜ ìŠ¤í¬ë¡¤ (ë” ìì—°ìŠ¤ëŸ¬ìš´ ë™ì‘)
        driver.execute_script("window.scrollBy(0, 300)")
        time.sleep(random.uniform(0.5, 1.5))
        
        soup = BeautifulSoup(driver.page_source, "html.parser")
        driver.quit()
        
        # ì—¬ëŸ¬ ì„ íƒì ì‹œë„
        related = []
        for selector in [SELECTORS["related_keywords"], SELECTORS["related_keywords_alt"], SELECTORS["related_keywords_alt2"]]:
            related = soup.select(selector)
            if related:
                logger.info(f"âœ… Seleniumìœ¼ë¡œ ì„ íƒì '{selector}'ì—ì„œ {len(related)}ê°œ í‚¤ì›Œë“œ ì°¾ìŒ")
                break
                
        result = [tag.get_text().strip() for tag in related] if related else []
        if not result:
            logger.warning(f"âš ï¸ {keyword}: Seleniumìœ¼ë¡œë„ ì—°ê´€ í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        return result
        
    except Exception as e:
        logger.error(f"âŒ Selenium í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {e}")
        return []

# ë„¤ì´ë²„ APIë¥¼ í™œìš©í•œ ê´€ë ¨ ê²€ìƒ‰ì–´ ìˆ˜ì§‘ (ëŒ€ì²´ ì ‘ê·¼ë²•)
def get_related_keywords_api(keyword):
    logger = logging.getLogger()
    logger.info(f"ğŸ”„ {keyword}: API ìš”ì²­ ì‹œë„")
    
    # URL ì¸ì½”ë”©
    encoded_keyword = urllib.parse.quote(keyword)
    url = f"https://ac.shopping.naver.com/ac?frm=shopping&q={encoded_keyword}&q_enc=UTF-8&s=1&r=1"
    
    headers = {
        "User-Agent": f"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/{random.randint(90, 110)}.0.{random.randint(4000, 5000)}.{random.randint(100, 200)} Safari/537.36",
        "Referer": "https://shopping.naver.com/",
        "Accept": "application/json",
    }
    
    try:
        time.sleep(random.uniform(0.5, 1.5))
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        data = response.json()
        # ì˜ˆìƒë˜ëŠ” JSON êµ¬ì¡°ì— ë”°ë¼ ê²°ê³¼ ì¶”ì¶œ
        items = []
        if "items" in data and len(data["items"]) > 0:
            for item_group in data["items"]:
                if isinstance(item_group, list):
                    for item in item_group:
                        if isinstance(item, list) and len(item) > 0:
                            items.append(item[0])
        
        if items:
            logger.info(f"âœ… APIì—ì„œ {len(items)}ê°œ í‚¤ì›Œë“œ ì°¾ìŒ")
            return items
        else:
            logger.warning(f"âš ï¸ {keyword}: APIì—ì„œ ì—°ê´€ í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return []
            
    except Exception as e:
        logger.error(f"âŒ API ìš”ì²­ ì¤‘ ì˜¤ë¥˜: {e}")
        return []

# ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ í¬ë¡¤ë§ í•¨ìˆ˜
def get_related_keywords_with_retry(keyword, max_retries=3):
    logger = logging.getLogger()
    logger.info(f"ğŸ” '{keyword}' ì—°ê´€ í‚¤ì›Œë“œ ìˆ˜ì§‘ ì‹œì‘")
    
    for attempt in range(max_retries):
        try:
            # 1. ì¼ë°˜ ìš”ì²­ ì‹œë„
            keywords = get_related_keywords(keyword)
            if keywords:
                return keywords
            
            # 2. API ìš”ì²­ ì‹œë„
            logger.info(f"ì¼ë°˜ ìš”ì²­ ì‹¤íŒ¨, API ì‚¬ìš© ì‹œë„ ì¤‘ ({attempt+1}/{max_retries})")
            keywords = get_related_keywords_api(keyword)
            if keywords:
                return keywords
                
            # 3. Selenium ì‹œë„
            logger.info(f"API ìš”ì²­ ì‹¤íŒ¨, Selenium ì‚¬ìš© ì‹œë„ ì¤‘ ({attempt+1}/{max_retries})")
            keywords = get_related_keywords_selenium(keyword)
            if keywords:
                return keywords
                
        except Exception as e:
            logger.error(f"ì‹œë„ {attempt+1}/{max_retries} ì‹¤íŒ¨: {e}")
        
        if attempt < max_retries - 1:
            wait_time = 5 * (attempt + 1)  # ì ì§„ì  ëŒ€ê¸° ì‹œê°„ ì¦ê°€
            logger.info(f"â±ï¸ {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
            time.sleep(wait_time)
    
    logger.error(f"âŒ '{keyword}' ì—°ê´€ í‚¤ì›Œë“œ ìˆ˜ì§‘ ì‹¤íŒ¨ (ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ì´ˆê³¼)")
    return []

# ë°°ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜
def process_keyword_batch(batch_items, sheet):
    logger = logging.getLogger()
    results = {"success": 0, "fail": 0}
    
    for idx, keyword in batch_items:
        try:
            related_keywords = get_related_keywords_with_retry(keyword)
            
            if related_keywords:
                # ì—°ê´€ í‚¤ì›Œë“œ ì—…ë°ì´íŠ¸
                sheet.update_cell(idx, 5, ", ".join(related_keywords))  # ì—°ê´€ í‚¤ì›Œë“œ ì—…ë°ì´íŠ¸
                sheet.update_cell(idx, 1, idx-1)  # No ê°’ ì—…ë°ì´íŠ¸
                sheet.update_cell(idx, 2, datetime.now().strftime('%Y-%m-%d %H:%M:%S'))  # ë‚ ì§œ ì—…ë°ì´íŠ¸
                sheet.update_cell(idx, 4, "ìˆ˜ì§‘ ì™„ë£Œ")  # ìˆ˜ì§‘ ì—¬ë¶€ í‘œì‹œ
                logger.info(f"âœ… '{keyword}' ì—°ê´€ í‚¤ì›Œë“œ ìˆ˜ì§‘ ë° ì—…ë°ì´íŠ¸ ì™„ë£Œ ({len(related_keywords)}ê°œ)")
                results["success"] += 1
            else:
                sheet.update_cell(idx, 4, "ìˆ˜ì§‘ ì‹¤íŒ¨")  # ìˆ˜ì§‘ ì‹¤íŒ¨ í‘œì‹œ
                logger.warning(f"âš ï¸ '{keyword}' ì—°ê´€ í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                results["fail"] += 1
                
        except Exception as e:
            logger.error(f"âŒ '{keyword}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            try:
                sheet.update_cell(idx, 4, "ì˜¤ë¥˜ ë°œìƒ")
            except:
                pass
            results["fail"] += 1
            
    return results

# ì‹¤í–‰ í•¨ìˆ˜
def main():
    logger = setup_logging()
    logger.info("ğŸš€ í‚¤ì›Œë“œ ìˆ˜ì§‘ê¸° ì‹¤í–‰ ì‹œì‘")
    
    # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì„¤ì •
    SHEET_ID = "1wxvKTda74w3KwyopgYAwAO3cgkShq6itMfS4GCE6Gp0"  # Google Sheets ID
    WORKSHEET_NAME = "ì‹œíŠ¸1"  # ì‹œíŠ¸ íƒ­ ì´ë¦„
    
    total_stats = {"processed": 0, "success": 0, "fail": 0}
    
    try:
        sheet = connect_google_sheet(SHEET_ID, WORKSHEET_NAME)
        rows = sheet.get_all_records()
        logger.info(f"ğŸ“Š ì´ {len(rows)}ê°œ í–‰ ë¡œë“œë¨")
        
        # ì²˜ë¦¬í•  í‚¤ì›Œë“œ í•„í„°ë§
        keywords_to_process = []
        for idx, row in enumerate(rows, start=2):  # ì²« ë²ˆì§¸ í–‰ì€ í—¤ë”
            keyword = row.get("í‚¤ì›Œë“œ", "").strip()
            existing_related_keywords = row.get("ì—°ê´€í‚¤ì›Œë“œ", "").strip()
            
            if not keyword:
                logger.debug(f"í–‰ {idx}: í‚¤ì›Œë“œ ì—†ìŒ, ê±´ë„ˆëœ€")
                continue
                
            if existing_related_keywords:
                logger.debug(f"í–‰ {idx}: '{keyword}' ì´ë¯¸ ì—°ê´€ í‚¤ì›Œë“œ ìˆìŒ, ê±´ë„ˆëœ€")
                continue
                
            keywords_to_process.append((idx, keyword))
            
        logger.info(f"ğŸ” ì²˜ë¦¬í•  í‚¤ì›Œë“œ {len(keywords_to_process)}ê°œ ë°œê²¬")
        
        if not keywords_to_process:
            logger.info("âœ… ì²˜ë¦¬í•  í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
            return
            
        # ë°°ì¹˜ ì²˜ë¦¬ - ë³‘ë ¬ ì²˜ë¦¬ ëŒ€ì‹  ìˆœì°¨ ì²˜ë¦¬ë¡œ ë³€ê²½ (ë´‡ íƒì§€ ë°©ì§€)
        batch_size = 1  # í•œ ë²ˆì— ì²˜ë¦¬í•  í‚¤ì›Œë“œ ìˆ˜ (1ë¡œ ì¤„ì„)
        total_batches = (len(keywords_to_process) + batch_size - 1) // batch_size
        
        for i in range(0, len(keywords_to_process), batch_size):
            batch = keywords_to_process[i:i+batch_size]
            logger.info(f"ğŸ“¦ ë°°ì¹˜ {i//batch_size + 1}/{total_batches} ì²˜ë¦¬ ì‹œì‘ ({len(batch)}ê°œ í‚¤ì›Œë“œ)")
            
            # ìˆœì°¨ ì²˜ë¦¬
            result = process_keyword_batch(batch, sheet)
            total_stats["success"] += result["success"]
            total_stats["fail"] += result["fail"]
            total_stats["processed"] += result["success"] + result["fail"]
            
            # ë°°ì¹˜ ê°„ ëŒ€ê¸° ì‹œê°„ ì¶”ê°€ (ë´‡ íƒì§€ ë°©ì§€)
            if i + batch_size < len(keywords_to_process):
                wait_time = random.uniform(10, 20)  # 10-20ì´ˆ ëŒ€ê¸°
                logger.info(f"â±ï¸ ë‹¤ìŒ ë°°ì¹˜ê¹Œì§€ {wait_time:.1f}ì´ˆ ëŒ€ê¸°...")
                time.sleep(wait_time)
        
        logger.info(f"âœ… ì‘ì—… ì™„ë£Œ: ì´ {total_stats['processed']}ê°œ ì²˜ë¦¬, ì„±ê³µ: {total_stats['success']}, ì‹¤íŒ¨: {total_stats['fail']}")
        
    except Exception as e:
        logger.error(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

# ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    main()
